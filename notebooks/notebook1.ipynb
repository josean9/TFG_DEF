{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9e57c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\josit\\CUARTO CURSO\\TFG\\TFG_DEF\\envproc1\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\josit\\CUARTO CURSO\\TFG\\TFG_DEF\\envproc1\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# --- LIMPIADOR DE NOTICIAS FOMC CON FINBERT ---\n",
    "# ============================================================\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ====================================================\n",
    "# --- 1Ô∏è‚É£ Rutas ---\n",
    "# ====================================================\n",
    "ruta_origen = \"../data/csv/noticias_con_sentimiento.csv\"   # CSV con texto completo\n",
    "ruta_destino = \"../data/csv/fomc_sentiment_finbert_clean.csv\"  # salida limpia\n",
    "\n",
    "# ====================================================\n",
    "# --- 2Ô∏è‚É£ Cargar CSV original ---\n",
    "# ====================================================\n",
    "df = pd.read_csv(ruta_origen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d56f8d52",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# --- Distribuci√≥n de Sentiment_Score ---\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n\u001b[32m      7\u001b[39m \n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Aseguramos nombre correcto (min√∫sculas)\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ============================================================\n",
    "# --- Distribuci√≥n de Sentiment_Score ---\n",
    "# ============================================================\n",
    "\n",
    "# Aseguramos nombre correcto (min√∫sculas)\n",
    "col_sent = [c for c in df.columns if \"sentiment_score\" in c.lower()][0]\n",
    "\n",
    "plt.figure(figsize=(9,5))\n",
    "sns.histplot(df[col_sent], bins=30, kde=True, color=\"#0083B0\", edgecolor=\"white\")\n",
    "\n",
    "plt.title(\"Distribuci√≥n de Sentiment_Score\", fontsize=14, weight=\"bold\")\n",
    "plt.xlabel(\"Sentiment_Score (de -1 a 1)\")\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.axvline(0, color='black', linestyle='--', linewidth=1)\n",
    "plt.show()\n",
    "\n",
    "# Informaci√≥n complementaria\n",
    "print(\"üìä Estad√≠sticas b√°sicas del Sentiment_Score:\")\n",
    "print(df[col_sent].describe().round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bb7da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Noticias cargadas: 419 registros\n",
      "  release_date                                               text\n",
      "0   2025-05-28  Minutes of the Federal Open Market Committee\\n...\n",
      "1   2025-05-07  Although swings in net exports have affected t...\n",
      "\n",
      "üì¶ Cargando modelo FinBERT (ProsusAI/finbert, versi√≥n TensorFlow)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\josit\\CUARTO CURSO\\APRENDIZAJE AUTOMATICO\\Caso02_Prediccion_BBVA_SANTANDER\\envproc\\Lib\\site-packages\\huggingface_hub\\file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\josit\\CUARTO CURSO\\APRENDIZAJE AUTOMATICO\\Caso02_Prediccion_BBVA_SANTANDER\\envproc\\Lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\josit\\CUARTO CURSO\\APRENDIZAJE AUTOMATICO\\Caso02_Prediccion_BBVA_SANTANDER\\envproc\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß† Analizando sentimiento de cada noticia...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 419/419 [02:27<00:00,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Archivo limpio guardado correctamente en:\n",
      "C:\\Users\\josit\\CUARTO CURSO\\APRENDIZAJE AUTOMATICO\\Caso02_Prediccion_BBVA_SANTANDER\\data\\csv\\fomc_sentiment_finbert_clean.csv\n",
      "  release_date sentiment_label  sentiment_score\n",
      "0   2025-05-28         neutral           0.3628\n",
      "1   2025-05-07        positive           0.3796\n",
      "2   2025-03-19        negative           0.4154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# --- LIMPIEZA Y AN√ÅLISIS DE NOTICIAS FOMC CON FINBERT (TF) ---\n",
    "# ============================================================\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification, pipeline\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ====================================================\n",
    "# --- 1Ô∏è‚É£ Rutas ---\n",
    "# ====================================================\n",
    "ruta_origen = \"../data/csv/noticias_con_sentimiento.csv\"   # CSV con texto completo\n",
    "ruta_destino = \"../data/csv/fomc_sentiment_finbert_clean.csv\"  # salida limpia\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# --- 2Ô∏è‚É£ Cargar CSV y seleccionar columnas ---\n",
    "# ====================================================\n",
    "df = pd.read_csv(ruta_origen, encoding=\"utf-8\", on_bad_lines=\"skip\")\n",
    "\n",
    "# Nos quedamos solo con 'Release Date' y 'Text'\n",
    "df = df[['Release Date', 'Text']].dropna()\n",
    "df.columns = ['release_date', 'text']\n",
    "df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce')\n",
    "df = df.dropna(subset=['release_date', 'text'])\n",
    "\n",
    "print(f\"‚úÖ Noticias cargadas: {len(df)} registros\")\n",
    "print(df.head(2))\n",
    "\n",
    "# ====================================================\n",
    "# --- 3Ô∏è‚É£ Cargar modelo FinBERT (TensorFlow) ---\n",
    "# ====================================================\n",
    "print(\"\\nüì¶ Cargando modelo FinBERT (ProsusAI/finbert, versi√≥n TensorFlow)...\")\n",
    "model_name = \"ProsusAI/finbert\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "finbert = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    framework=\"tf\",   # importante: fuerza TensorFlow\n",
    "    return_all_scores=False\n",
    ")\n",
    "\n",
    "# ====================================================\n",
    "# --- 4Ô∏è‚É£ Analizar sentimiento con FinBERT ---\n",
    "# ====================================================\n",
    "labels, scores = [], []\n",
    "\n",
    "print(\"\\nüß† Analizando sentimiento de cada noticia...\\n\")\n",
    "\n",
    "for text in tqdm(df['text'].astype(str), total=len(df)):\n",
    "    try:\n",
    "        res = finbert(text[:512])  # FinBERT solo acepta hasta 512 tokens\n",
    "        labels.append(res[0]['label'].lower())\n",
    "        scores.append(round(res[0]['score'], 4))\n",
    "    except Exception:\n",
    "        labels.append(\"neutral\")\n",
    "        scores.append(0.0)\n",
    "\n",
    "# ====================================================\n",
    "# --- 5Ô∏è‚É£ Crear nuevo CSV limpio ---\n",
    "# ====================================================\n",
    "df_clean = pd.DataFrame({\n",
    "    'release_date': df['release_date'],\n",
    "    'sentiment_label': labels,\n",
    "    'sentiment_score': scores\n",
    "})\n",
    "\n",
    "df_clean.to_csv(ruta_destino, index=False)\n",
    "print(f\"\\n‚úÖ Archivo limpio guardado correctamente en:\\n{ruta_destino}\")\n",
    "\n",
    "print(df_clean.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5b7bbf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas: ['Date', 'Release Date', 'Type', 'Text', 'Sentiment_Score', 'Sentiment_Label']\n",
      "N√∫mero de filas: 448\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Type</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment_Score</th>\n",
       "      <th>Sentiment_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-05-07</td>\n",
       "      <td>2025-05-28</td>\n",
       "      <td>Minute</td>\n",
       "      <td>Minutes of the Federal Open Market Committee\\n...</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-05-07</td>\n",
       "      <td>2025-05-07</td>\n",
       "      <td>Statement</td>\n",
       "      <td>Although swings in net exports have affected t...</td>\n",
       "      <td>0.6249</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>Statement</td>\n",
       "      <td>Recent indicators suggest that economic activi...</td>\n",
       "      <td>0.9306</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Release Date       Type  \\\n",
       "0  2025-05-07   2025-05-28     Minute   \n",
       "1  2025-05-07   2025-05-07  Statement   \n",
       "2  2025-03-19   2025-03-19  Statement   \n",
       "\n",
       "                                                Text  Sentiment_Score  \\\n",
       "0  Minutes of the Federal Open Market Committee\\n...           0.9999   \n",
       "1  Although swings in net exports have affected t...           0.6249   \n",
       "2  Recent indicators suggest that economic activi...           0.9306   \n",
       "\n",
       "  Sentiment_Label  \n",
       "0        positive  \n",
       "1        positive  \n",
       "2        positive  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Columnas:\", df.columns.tolist())\n",
    "print(\"N√∫mero de filas:\", len(df))\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07cca4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset extendido correctamente con eventos 2000‚Äì2025 guardado en:\n",
      "C:\\Users\\josit\\CUARTO CURSO\\APRENDIZAJE AUTOMATICO\\Caso02_Prediccion_BBVA_SANTANDER\\data\\csv\\fomc_sentiment_extended_recent.csv\n",
      "\n",
      "üìä Vista previa:\n",
      "    release_date sentiment_label  sentiment_score                fuente  \\\n",
      "430   2024-11-26         neutral           0.3650             FOMC real   \n",
      "431   2024-12-18        negative           0.4177             FOMC real   \n",
      "432   2025-01-08         neutral           0.3661             FOMC real   \n",
      "433   2025-01-29        positive           0.3751             FOMC real   \n",
      "434   2025-02-10        positive           0.6000  Hist√≥rico artificial   \n",
      "435   2025-02-19         neutral           0.3728             FOMC real   \n",
      "436   2025-03-19        negative           0.4154             FOMC real   \n",
      "437   2025-04-09         neutral           0.3606             FOMC real   \n",
      "438   2025-05-07        positive           0.3796             FOMC real   \n",
      "439   2025-05-28         neutral           0.3628             FOMC real   \n",
      "\n",
      "     Sentiment_Value                                         Evento  \n",
      "430              NaN                                            NaN  \n",
      "431              NaN                                            NaN  \n",
      "432              NaN                                            NaN  \n",
      "433              NaN                                            NaN  \n",
      "434              0.6  Mercados optimistas ante bajada de tipos 2025  \n",
      "435              NaN                                            NaN  \n",
      "436              NaN                                            NaN  \n",
      "437              NaN                                            NaN  \n",
      "438              NaN                                            NaN  \n",
      "439              NaN                                            NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# ============================================================\n",
    "# --- 1Ô∏è‚É£ Cargar CSV original FinBERT limpio ---\n",
    "# ============================================================\n",
    "ruta_origen = r\"C:\\Users\\josit\\CUARTO CURSO\\APRENDIZAJE AUTOMATICO\\Caso02_Prediccion_BBVA_SANTANDER\\data\\csv\\fomc_sentiment_finbert_clean.csv\"\n",
    "df = pd.read_csv(ruta_origen)\n",
    "\n",
    "# Normalizar nombres por si acaso\n",
    "df.columns = [c.strip().lower() for c in df.columns]\n",
    "df.rename(columns={\"release_date\": \"release_date\"}, inplace=True)\n",
    "\n",
    "df[\"release_date\"] = pd.to_datetime(df[\"release_date\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"release_date\"]).copy()\n",
    "df[\"fuente\"] = \"FOMC real\"\n",
    "\n",
    "# ============================================================\n",
    "# --- 2Ô∏è‚É£ Crear lista de eventos hist√≥ricos artificiales ---\n",
    "# ============================================================\n",
    "eventos = [\n",
    "    # üß® CRISIS Y DESASTRES ECON√ìMICOS\n",
    "    {\"release_date\": datetime(2000, 3, 10), \"Sentiment_Value\": -0.7, \"Evento\": \"Pinchazo burbuja punto-com\"},\n",
    "    {\"release_date\": datetime(2001, 9, 11), \"Sentiment_Value\": -1.0, \"Evento\": \"Atentados del 11-S\"},\n",
    "    {\"release_date\": datetime(2003, 3, 20), \"Sentiment_Value\": -0.8, \"Evento\": \"Inicio guerra de Irak\"},\n",
    "    {\"release_date\": datetime(2008, 9, 15), \"Sentiment_Value\": -1.0, \"Evento\": \"Quiebra Lehman Brothers - crisis financiera global\"},\n",
    "    {\"release_date\": datetime(2010, 5, 6),  \"Sentiment_Value\": -0.7, \"Evento\": \"Flash Crash en Wall Street\"},\n",
    "    {\"release_date\": datetime(2011, 8, 8),  \"Sentiment_Value\": -0.8, \"Evento\": \"EE. UU. pierde calificaci√≥n AAA\"},\n",
    "    {\"release_date\": datetime(2012, 6, 9),  \"Sentiment_Value\": -0.7, \"Evento\": \"Crisis de deuda en Espa√±a - rescate bancario\"},\n",
    "    {\"release_date\": datetime(2016, 6, 24), \"Sentiment_Value\": -0.7, \"Evento\": \"Refer√©ndum Brexit\"},\n",
    "    {\"release_date\": datetime(2020, 3, 16), \"Sentiment_Value\": -1.0, \"Evento\": \"Crash global por COVID-19\"},\n",
    "    {\"release_date\": datetime(2022, 2, 24), \"Sentiment_Value\": -0.9, \"Evento\": \"Inicio guerra Rusia-Ucrania\"},\n",
    "    {\"release_date\": datetime(2023, 3, 10), \"Sentiment_Value\": -0.8, \"Evento\": \"Colapso del Silicon Valley Bank\"},\n",
    "\n",
    "    # üí∞ RECUPERACIONES Y POL√çTICAS MONETARIAS POSITIVAS\n",
    "    {\"release_date\": datetime(2009, 3, 9),  \"Sentiment_Value\": +0.8, \"Evento\": \"Inicio de expansi√≥n cuantitativa (QE) - FED\"},\n",
    "    {\"release_date\": datetime(2012, 7, 26), \"Sentiment_Value\": +0.7, \"Evento\": \"Draghi: 'Har√© lo que sea necesario' (BCE)\"},\n",
    "    {\"release_date\": datetime(2020, 3, 23), \"Sentiment_Value\": +0.9, \"Evento\": \"FED lanza est√≠mulos masivos durante COVID\"},\n",
    "    {\"release_date\": datetime(2021, 11, 8), \"Sentiment_Value\": +0.7, \"Evento\": \"Reapertura econ√≥mica global post-COVID\"},\n",
    "    {\"release_date\": datetime(2023, 11, 1), \"Sentiment_Value\": +0.5, \"Evento\": \"FED desacelera subidas de tipos\"},\n",
    "\n",
    "    # üåç OTROS EVENTOS GLOBALES RELEVANTES\n",
    "    {\"release_date\": datetime(2007, 6, 29), \"Sentiment_Value\": +0.5, \"Evento\": \"Lanzamiento del iPhone - auge tecnol√≥gico\"},\n",
    "    {\"release_date\": datetime(2019, 3, 11), \"Sentiment_Value\": -0.8, \"Evento\": \"Muerte del presidente del Santander\"},\n",
    "    {\"release_date\": datetime(2021, 1, 6),  \"Sentiment_Value\": -0.5, \"Evento\": \"Asalto al Capitolio de EE. UU.\"},\n",
    "    {\"release_date\": datetime(2024, 11, 5), \"Sentiment_Value\": -0.4, \"Evento\": \"Elecciones presidenciales polarizadas EE. UU.\"},\n",
    "    {\"release_date\": datetime(2025, 2, 10), \"Sentiment_Value\": +0.6, \"Evento\": \"Mercados optimistas ante bajada de tipos 2025\"}\n",
    "]\n",
    "\n",
    "df_eventos = pd.DataFrame(eventos)\n",
    "\n",
    "# ============================================================\n",
    "# --- 3Ô∏è‚É£ Calcular label y score coherentes ---\n",
    "# ============================================================\n",
    "\n",
    "def label_from_value(v, thr=0.05):\n",
    "    if v > thr: return \"positive\"\n",
    "    elif v < -thr: return \"negative\"\n",
    "    else: return \"neutral\"\n",
    "\n",
    "def score_from_value(v):\n",
    "    return abs(round(float(v), 4))\n",
    "\n",
    "df_eventos[\"sentiment_label\"] = df_eventos[\"Sentiment_Value\"].apply(label_from_value)\n",
    "df_eventos[\"sentiment_score\"] = df_eventos[\"Sentiment_Value\"].apply(score_from_value)\n",
    "df_eventos[\"fuente\"] = \"Hist√≥rico artificial\"\n",
    "\n",
    "# ============================================================\n",
    "# --- 4Ô∏è‚É£ Unificar estructura (igual que el CSV original) ---\n",
    "# ============================================================\n",
    "\n",
    "# Seleccionar columnas en el orden original + las nuevas\n",
    "columnas_finales = [\n",
    "    \"release_date\", \"sentiment_label\", \"sentiment_score\",\n",
    "    \"fuente\", \"Sentiment_Value\", \"Evento\"\n",
    "]\n",
    "\n",
    "df_extendido = pd.concat([df, df_eventos[columnas_finales]], ignore_index=True)\n",
    "df_extendido = df_extendido.sort_values(\"release_date\").reset_index(drop=True)\n",
    "\n",
    "# ============================================================\n",
    "# --- 5Ô∏è‚É£ Guardar CSV final extendido ---\n",
    "# ============================================================\n",
    "ruta_guardado = r\"C:\\Users\\josit\\CUARTO CURSO\\APRENDIZAJE AUTOMATICO\\Caso02_Prediccion_BBVA_SANTANDER\\data\\csv\\fomc_sentiment_extended_recent.csv\"\n",
    "df_extendido.to_csv(ruta_guardado, index=False)\n",
    "\n",
    "print(f\"‚úÖ Dataset extendido correctamente con eventos 2000‚Äì2025 guardado en:\\n{ruta_guardado}\")\n",
    "print(\"\\nüìä Vista previa:\")\n",
    "print(df_extendido.tail(10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envproc1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
